{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **RNSA Breast Cancer Detector.**\n",
    "\n",
    "## ML:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Librerias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerias\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pydicom\n",
    "from pathlib import Path\n",
    "\n",
    "#Constantes\n",
    "IMGFOLDER_PATH = \"../data/raw/train_images\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Dataset...\n",
      "==========\n",
      "\n",
      "Dataset dimensions: (54668, 11)\n",
      "\n",
      "Data Preview:\n",
      "\n",
      "   patient_id    image_id   age  cancer  biopsy  invasive  BIRADS  implant  \\\n",
      "0       10006   462822612  61.0       0       0         0     4.0        0   \n",
      "1       10006  1459541791  61.0       0       0         0     4.0        0   \n",
      "2       10006  1864590858  61.0       0       0         0     4.0        0   \n",
      "3       10006  1874946579  61.0       0       0         0     4.0        0   \n",
      "4       10011   220375232  55.0       0       0         0     0.0        0   \n",
      "\n",
      "   density  laterality  view  \n",
      "0      2.0         0.0   0.0  \n",
      "1      2.0         0.0   1.0  \n",
      "2      2.0         1.0   1.0  \n",
      "3      2.0         1.0   0.0  \n",
      "4      1.0         0.0   0.0  \n",
      "\n",
      " · Successfully data readed\n"
     ]
    }
   ],
   "source": [
    "def ReadData():\n",
    "    print(\"Reading Dataset...\\n==========\\n\")\n",
    "\n",
    "    try:\n",
    "        data = pd.read_csv(\"../data/processed/clean_data.csv\")\n",
    "        print(f\"Dataset dimensions: {data.shape}\\n\\nData Preview:\\n\\n{data.head(5)}\\n\\n · Successfully data readed\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"...Failed data readed. Error: {e}\")\n",
    "        return None\n",
    "\n",
    "data = ReadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetPaths(root, dataset):\n",
    "\n",
    "    #Creamos una lista con el Path de las imagenes.\n",
    "\n",
    "    root = Path(root) # conversion Str -> Path\n",
    "    list_path = list(root.rglob(\"*.dcm\")) # lista de paths\n",
    "\n",
    "    #Mapeamos\n",
    "    map_label = {}\n",
    "\n",
    "    for p in list_path:\n",
    "        patient_id = p.parts[-2] # -> folder del paciente donde están las imagenes.\n",
    "        img_id = p.stem # -> la imagen en cuestion.\n",
    "\n",
    "        try:    \n",
    "            filter = dataset[(dataset[\"patient_id\"].astype(str) == patient_id) & (dataset[\"image_id\"].astype(str) == img_id)] #Importante convertir los valores del dataset en str para la comparacion.\n",
    "\n",
    "            if not filter.empty:\n",
    "                target = int(filter[\"cancer\"].values[0]) # -> tomamos el valor del target.\n",
    "                map_label[p] = target\n",
    "            else:\n",
    "                print(\"No coincidences in dataset.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e} in row {p}.\")\n",
    "\n",
    "    return map_label\n",
    "\n",
    "\n",
    "\n",
    "mappingIMG = GetPaths(IMGFOLDER_PATH, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primero vamos a crear una pequeña funcion para normalizar el tamaño de las imagenes.\n",
    "\n",
    "def NormalizeIMG(img):\n",
    "    \n",
    "    max_val = np.max(img)\n",
    "    img = img.astype(np.float32)\n",
    "\n",
    "    if max_val > 0:\n",
    "        img = img / max_val\n",
    "\n",
    "    #Vamos a hacer una verificación adicional para convertir las imagenes en escala de grises a RGB si fuese necesario.\n",
    "    \n",
    "    if img.ndim == 2: #Escala de grises -> 1 dimension + canal\n",
    "        img = np.stack([img] * 3, axis=-1)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos las imagenes.\n",
    "def ImgLoader(path):\n",
    "\n",
    "    #Convertimos los paths de tf.str a str normal porque si no falla.\n",
    "    try:\n",
    "        str_path = path.numpy().decode(\"utf-8\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "    #Cargamos imgs dicom\n",
    "    dcm = pydicom.dcmread(str_path)\n",
    "    img = dcm.pixel_array.astype(np.float32)\n",
    "\n",
    "    #Normalizamos el tamaño de las imagenes\n",
    "    img = NormalizeIMG(img)\n",
    "    img = tf.image.resize(img, [224,224]) #Redimensionamos a 244x244\n",
    "\n",
    "    #Convertimos la img a tensor\n",
    "\n",
    "    img_tensor = tf.convert_to_tensor(img)\n",
    "\n",
    "    return img_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lo convertimos en tensores\n",
    "def ImgToTensor(path, label):\n",
    "    img = tf.py_function(func=ImgLoader, inp=[path], Tout=tf.float32)\n",
    "    img.set_shape([224, 224, 3]) #Seteamos la imagen a 3 canales\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TensorMaker(datalabels):\n",
    "\n",
    "    #Convertimos el diccionario en listas separando key y value.\n",
    "    paths = list(datalabels.keys())\n",
    "    labels = list(datalabels.values())\n",
    "\n",
    "    #convertimos las listas en tensores.\n",
    "    path_list = []\n",
    "    label_list = []\n",
    "\n",
    "    for p, l in zip(paths, labels):\n",
    "        path_list.append(str(p)) #Path -> str\n",
    "        label_list.append(l)\n",
    "\n",
    "    tensor_paths = tf.constant(path_list)\n",
    "    tensor_labels = tf.constant(label_list, dtype=tf.int32)\n",
    "\n",
    "    #Crearmos el dataframe con los tensores.\n",
    "    data_tensor = tf.data.Dataset.from_tensor_slices((tensor_paths, tensor_labels))\n",
    "\n",
    "    data_tensor = data_tensor.map(ImgToTensor, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    #Aplicamos el batching y el prefetching\n",
    "    data_tensor = data_tensor.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return data_tensor\n",
    "\n",
    "dataTensor = TensorMaker(mappingIMG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (32, 224, 224, 3)\n",
      "Label batch shape: (32,)\n"
     ]
    }
   ],
   "source": [
    "#Vamos a comprobar que se haya creado bien el dataset.\n",
    "\n",
    "for img, label in dataTensor.take(1):\n",
    "    print(f\"Image shape: {img.shape}\")\n",
    "    print(f\"Label batch shape: {label.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
